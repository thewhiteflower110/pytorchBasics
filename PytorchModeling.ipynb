{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PytorchModeling.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MWiqZL6aTXl2",
        "6rEWzVDwqE8B",
        "iFIwwmrDqQMu",
        "KMfRfThSvqqB",
        "6amQMn3y33qs",
        "V9FIb3QJpDcT",
        "P2XG3mnOgWU1",
        "3c2nlpaMhZ-8"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5b03456f70f5458885da0fb57858bc7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad2c177b01e34d28baf9ea18b76456a3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6dfd8cabb6244979b13202b86c028a85",
              "IPY_MODEL_8fedb822cefb427dbf1193c10ce7305f"
            ]
          }
        },
        "ad2c177b01e34d28baf9ea18b76456a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6dfd8cabb6244979b13202b86c028a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ff9a1b4a08774c439e96cb38cb4a7247",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4486347bdd1c4af69f4516c766f524a6"
          }
        },
        "8fedb822cefb427dbf1193c10ce7305f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_37dcf61b9ccc444b8f601f2f004f60a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:33&lt;00:00, 16.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_327fa719da964db79316a460174fa836"
          }
        },
        "ff9a1b4a08774c439e96cb38cb4a7247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4486347bdd1c4af69f4516c766f524a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "37dcf61b9ccc444b8f601f2f004f60a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "327fa719da964db79316a460174fa836": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr8HSM8VQ-6p"
      },
      "source": [
        "#import libraries\n",
        "import torch\n",
        "from torch.utils import data\n",
        "from torchvision import datasets,transforms\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch.nn.functional as f\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import optim\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import os\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_3WnMnW7qII"
      },
      "source": [
        "device='cuda'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWiqZL6aTXl2"
      },
      "source": [
        "# MNIST model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rEWzVDwqE8B"
      },
      "source": [
        "## getting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkWuGavFhPDt",
        "outputId": "d337f205-e2e2-471a-8c7f-7a452a6936ac"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-15 06:14:55--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-03-15 06:14:55--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: â€˜MNIST.tar.gzâ€™\n",
            "\n",
            "MNIST.tar.gz            [             <=>    ]  33.20M  11.1MB/s    in 3.0s    \n",
            "\n",
            "2021-03-15 06:14:59 (11.1 MB/s) - â€˜MNIST.tar.gzâ€™ saved [34813078]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93tfOvXOhTTH",
        "outputId": "800cb2e2-fae6-450b-d7d1-56859615d389"
      },
      "source": [
        "!tar -zxvf MNIST.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "584wi1WghtPI",
        "outputId": "40894e3c-833f-4eac-e6ba-009735dbed9b"
      },
      "source": [
        "root_dir = './'\n",
        "datasets.MNIST(root=root_dir,download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./\n",
              "    Split: Train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nkZwg2phggO"
      },
      "source": [
        "train_set = datasets.MNIST(root=root_dir, train=True, download=False, transform=transforms.ToTensor())\n",
        "test_set = datasets.MNIST(root=root_dir, train=False, download=False, transform=transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir5FM_zIRNYh"
      },
      "source": [
        "train_loader = data.DataLoader(train_set,batch_size=64,shuffle=True)\n",
        "test_loader = data.DataLoader(test_set,batch_size=64,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "ddn3yygpfdQN",
        "outputId": "a8851dbe-898b-4345-f32f-3621fb9af2f5"
      },
      "source": [
        "data_iter=iter(trainloader)\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "plt.imshow(images[0].numpy().squeeze(), cmap='Greys_r')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-cb8ecbda8b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vih3bgBp_q1"
      },
      "source": [
        "## 3 ways defining Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8mXk8CXivd0"
      },
      "source": [
        "class net(nn.Module): #why do we use this? inheritance\n",
        "  def __init__(self):\n",
        "    super().__init__() #why do we use this?\n",
        "    #inherits all th properties of nn.module, whoch provides lots of methods for easy use\n",
        "    self.hidden1=nn.Linear(784,128) #creates xW+b for 784 i/p and 128 o/p\n",
        "    self.hidden2=nn.Linear(128,64)\n",
        "    self.output=nn.Linear(64,10)\n",
        "  \n",
        "  def forward():\n",
        "    x=F.relu(self.hidden1(x))\n",
        "    x=F.relu(self.hidden2(x))\n",
        "    x=F.softmax(self.output(x),dim=1) #rows-> batch columns->softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvoYJbvBoaNN"
      },
      "source": [
        "from collections import OrderedDict\n",
        "input_size=784\n",
        "hidden_size=[128,64]\n",
        "output_size=10\n",
        "\n",
        "model=nn.Sequential(OrderedDict([\n",
        "                     ('fc1',nn.Linear(input_size,hidden_size[0])),\n",
        "                     ('relu1',nn.ReLU()),\n",
        "                     ('fc2',nn.Linear(hidden_size[0],hidden_size[1])),\n",
        "                    ('relu2',nn.ReLU()),\n",
        "                      ('fc3',nn.Linear(hidden_size[1],output_size)),\n",
        "                      ('softmax',nn.Softmax(dim=1))]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNiTPKVMpw-M"
      },
      "source": [
        "input_size=784\n",
        "hidden_size=[128,64]\n",
        "output_size=10\n",
        "\n",
        "model=nn.Sequential(\n",
        "                     nn.Linear(input_size,hidden_size[0]),\n",
        "                     nn.ReLU(),\n",
        "                    nn.Linear(hidden_size[0],hidden_size[1]),\n",
        "                    nn.ReLU(),\n",
        "                      nn.Linear(hidden_size[1],output_size),\n",
        "                     nn.Softmax(dim=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqUHpORBmUJN",
        "outputId": "4738381f-ffac-42ad-f4b4-254a00521d9e"
      },
      "source": [
        "model=net()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "net(\n",
            "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm2cbtKzmVdD",
        "outputId": "b6a25926-caef-4895-f1bb-2c8365da5204"
      },
      "source": [
        "#view the weights of first layer\n",
        "print(model.hidden1.weight)\n",
        "print(model.hidden1.weight.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 7.7773e-03,  2.6213e-02, -7.5765e-03,  ...,  1.9262e-02,\n",
            "          4.0357e-05,  1.9669e-02],\n",
            "        [ 2.3654e-02,  6.8337e-03,  2.7390e-02,  ..., -2.4977e-02,\n",
            "         -1.8353e-02,  3.9916e-03],\n",
            "        [-3.5160e-03, -3.0593e-02,  1.4294e-02,  ...,  2.6567e-02,\n",
            "         -2.2277e-02, -2.3799e-02],\n",
            "        ...,\n",
            "        [-3.1853e-02,  1.7903e-02,  2.4519e-02,  ...,  2.1167e-02,\n",
            "          1.8438e-02,  2.3090e-03],\n",
            "        [-3.3297e-02, -2.5045e-02,  2.2926e-02,  ..., -8.1689e-03,\n",
            "          2.9683e-02,  2.8208e-02],\n",
            "        [ 2.6598e-02,  1.9062e-02,  2.5593e-02,  ...,  1.6217e-02,\n",
            "         -1.6130e-03, -7.2461e-03]], requires_grad=True)\n",
            "torch.Size([128, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFIwwmrDqQMu"
      },
      "source": [
        "## Data transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM8UV6RunZN8",
        "outputId": "06959b90-e5ed-41d0-e816-d579897974f1"
      },
      "source": [
        "data_iter=iter(train_loader)\n",
        "images, labels = data_iter.next()\n",
        " \n",
        "images.resize(64,1,784) #(batch_size,channels, image pixels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/tensor.py:474: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv8uwPaXqzpa"
      },
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(params=model.parameters(), lr=0.01)\n",
        "epochs=2\n",
        "\n",
        "\n",
        "for e in range(epochs):\n",
        "  for images,labels in train_loader:\n",
        "\n",
        "    images=images.view(images.shape[0],-1) #reshaping to (64,784)\n",
        "    \n",
        "    optimizer.zero_grad() #clearing up the gradients of previous iteration\n",
        "\n",
        "    logits=model.forward(images)\n",
        "\n",
        "    loss=criterion(logits,labels)\n",
        "    loss.backward()\n",
        "    print(loss) #will print (train_size/batch_size)*epochs times\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnrLfmmjs23L"
      },
      "source": [
        "Crossentrop Loss calculates softmax on its own, and thus it can be ignored while declaring the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JInuSr8Vtbtm"
      },
      "source": [
        "gradients are accessed using .grade() function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMfRfThSvqqB"
      },
      "source": [
        "## testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYoapWjjsmfp"
      },
      "source": [
        "accuracy=0\n",
        "optimizer.zero_grad()\n",
        "for images,labels in test_loader:\n",
        "  images=images.view(images.shape[0],-1) #reshaping to (64,784)\n",
        "  probs=model(images)\n",
        "  #loss=criterion(probs,labels)\n",
        "  #print(loss)\n",
        "\n",
        "  top_p, top_class = probs.topk(1,dim=1)\n",
        "  equals = top_class == labels.view(*top_class.shape)\n",
        "  accuracy+= torch.mean(equals.type(torch.FloatTensor))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BeVciI3zOxv",
        "outputId": "366b6a51-4694-4833-d174-e5b79a7e5a9f"
      },
      "source": [
        "#printing accuracy\n",
        "(accuracy/len(test_loader)*100).item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.66202163696289"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da3kwshy0QHN"
      },
      "source": [
        "checkpoint={\n",
        "    'input_size':784,\n",
        "'hidden_size':[128,64],\n",
        "'output_size':10,\n",
        "'state_dict': model.state_dict()\n",
        "}\n",
        "torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPlkNMRJ0T35"
      },
      "source": [
        "#loading the  model\n",
        "\n",
        "\n",
        "model=nn.Sequential(OrderedDict([\n",
        "                     ('fc1',nn.Linear(input_size,hidden_size[0])),\n",
        "                     ('relu1',nn.ReLU()),\n",
        "                     ('fc2',nn.Linear(hidden_size[0],hidden_size[1])),\n",
        "                    ('relu2',nn.ReLU()),\n",
        "                      ('fc3',nn.Linear(hidden_size[1],output_size)),\n",
        "                      ('softmax',nn.Softmax(dim=1))]))\n",
        "\n",
        "checkpoint=torch.load('checkpoint.pth')\n",
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6amQMn3y33qs"
      },
      "source": [
        "# CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPSVvVU9-2YS"
      },
      "source": [
        "## Getting data ready"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc8DRltZ9HbQ",
        "outputId": "6a9c182c-6f60-433f-ef77-7ba77e363777"
      },
      "source": [
        "!wget -c https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-17 04:16:57--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: â€˜cifar-10-python.tar.gzâ€™\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  76.5MB/s    in 2.1s    \n",
            "\n",
            "2021-03-17 04:17:00 (76.5 MB/s) - â€˜cifar-10-python.tar.gzâ€™ saved [170498071/170498071]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAdQsR4K-8n0",
        "outputId": "4220fca3-b8cd-4d27-9ba8-e99aba3954c7"
      },
      "source": [
        "!tar -zxvf /content/cifar-10-python.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnDJwHQ__mF3"
      },
      "source": [
        "import _pickle as cPickle\n",
        "def load_batch(file1):\n",
        "    path = 'cifar-10-batches-py/'\n",
        "    #file = 'data_batch_1'\n",
        "\n",
        "    f = open(path+file1, 'rb')\n",
        "    dict = cPickle.load(f,encoding='latin1')\n",
        "    images = dict['data']\n",
        "    images = np.reshape(images, (10000, 3, 32, 32))\n",
        "    labels = dict['labels']\n",
        "    imagearray = np.array(images)   #   (10000, 3072)\n",
        "    labelarray = np.array(labels)   #   (10000,)\n",
        "    \n",
        "    return imagearray, labelarray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xxGOf3AVEi7"
      },
      "source": [
        "def split_and_add(new_arr):\n",
        "  im2=[]\n",
        "  for i in range(new_arr.shape[0]):\n",
        "    im=np.array(new_arr[i])\n",
        "    im2.append(im)\n",
        "  return im2\n",
        "\n",
        "def split_and_add_lab(new_arr):\n",
        "  im2=[]\n",
        "  for i in range(new_arr.shape[0]):\n",
        "    im=np.array(new_arr[i])\n",
        "    im2.append(im)\n",
        "  return im2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jD21-rfXxFN"
      },
      "source": [
        "#test=np.random.rand(10000, 3, 32, 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqeAHrsk_xF2"
      },
      "source": [
        "all_files=os.listdir('/content/cifar-10-batches-py')\n",
        "img_arr=[]\n",
        "lab_arr=[]\n",
        "test_img_arr=[]\n",
        "test_lab_arr=[]\n",
        "for i in all_files:\n",
        "  if i[0]=='d':\n",
        "    im,l=load_batch(i)\n",
        "    img_arr.extend(split_and_add(im))\n",
        "    lab_arr.extend(l)\n",
        "  elif i[0]=='t':\n",
        "    im,l=load_batch(i)\n",
        "    test_img_arr.extend(split_and_add(im))\n",
        "    test_lab_arr.extend(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qZH2wBenvaM",
        "outputId": "3dc3cc8a-8945-4796-dcce-f2c8313c55ea"
      },
      "source": [
        "len(lab_arr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXvokDrkSTix",
        "outputId": "f3d7f888-1f3f-4249-9671-984fc3242d4c"
      },
      "source": [
        "lab_arr[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-VnvXvQUnbx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "06e3ff70-d20f-43b1-c74f-9eb22c6c30ec"
      },
      "source": [
        "#the data is in format\n",
        "'''\n",
        "  [10000,3,32,32] x5\n",
        "  making it to -> [50000,3,32,32]\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n  [10000,3,32,32] x5\\n  making it to -> [50000,3,32,32]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io5iQFhcAfhP"
      },
      "source": [
        "class Cdataset(data.Dataset):\n",
        "  def __init__(self, img_arr,lab_arr ):\n",
        "    self.x_data = torch.tensor(img_arr,\n",
        "      dtype=torch.float32).to(device)\n",
        "    self.y_data = torch.tensor(lab_arr,\n",
        "      dtype=torch.long).to(device)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)  # required\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "    preds = self.x_data[idx]\n",
        "    pol = self.y_data[idx]\n",
        "    #sample = { 'image' : preds, 'label' : pol }\n",
        "    return preds,pol"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbxJrBxOLHHJ"
      },
      "source": [
        "train_data=Cdataset(img_arr,lab_arr)\n",
        "test_data=Cdataset(test_img_arr,test_lab_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS7PyJd7G9Da"
      },
      "source": [
        "train_loader=data.DataLoader(train_data,batch_size=32,shuffle=True)\n",
        "test_loader=data.DataLoader(test_data,batch_size=32,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy_RG-7PSV8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebba1dfa-d4e3-4359-ec3a-0e54669251fe"
      },
      "source": [
        "data_iter=iter(train_loader)\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([32, 3, 32, 32])\n",
            "torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CytJUHjE9DT_"
      },
      "source": [
        "## Defining model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDfH_Q-G35gj"
      },
      "source": [
        "class net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # torch.Size([32, 3, 32, 32])\n",
        "    self.conv1=nn.Conv2d(3,16,3) \n",
        "    # torch.Size([32, 16, 30, 30])\n",
        "    self.conv2=nn.Conv2d(16,32,3)\n",
        "    # torch.Size([32, 32, 28, 28])\n",
        "    self.maxpool1=nn.MaxPool2d(2)\n",
        "    # torch.Size([32, 32, 14, 14])\n",
        "    self.conv3=nn.Conv2d(32, 64, 3)\n",
        "    # torch.Size([32, 64, 12, 12])\n",
        "    self.conv4=nn.Conv2d(64, 128, 3)\n",
        "    # torch.Size([32, 128, 10, 10])\n",
        "    self.maxpool2=nn.MaxPool2d(2)\n",
        "    # torch.Size([32, 128, 5, 5])\n",
        "    self.flatten=nn.Flatten()\n",
        "    # torch.Size([32, 3200])\n",
        "    self.fc1=nn.Linear(3200 ,1204)\n",
        "    self.fc2=nn.Linear(1204,256)\n",
        "    self.fc3=nn.Linear(256,64)\n",
        "    self.fc4=nn.Linear(64,10) #10 classes\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=f.relu(self.conv1(x))\n",
        "    x=f.relu(self.conv2(x))\n",
        "    x=self.maxpool1(x)\n",
        "    x=f.relu(self.conv3(x))\n",
        "    x=f.relu(self.conv4(x))\n",
        "    x=self.maxpool2(x)\n",
        "    x=self.flatten(x)\n",
        "    x=f.relu(self.fc1(x))\n",
        "    x=f.relu(self.fc2(x))\n",
        "    x=f.relu(self.fc3(x))\n",
        "    x=f.softmax(self.fc4(x),dim=1)\n",
        "    return x\n",
        "    \n",
        "model=net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvCLgoMtT3Vq",
        "outputId": "dcf93c96-fa8f-4e0c-8134-dbb2de542c47"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "net(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=3200, out_features=1204, bias=True)\n",
            "  (fc2): Linear(in_features=1204, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kapdNDqFVGQS"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg83ar3o8b6-"
      },
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(params=model.parameters(),lr=0.03)\n",
        "epochs=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRkbMWc_Labi"
      },
      "source": [
        "for e in range(epochs):\n",
        "  for images,labels in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    logits=model(images)\n",
        "    loss=criterion(logits,labels)\n",
        "    loss.backward() #get the gradients\n",
        "    optimizer.step()# update the wieghts\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--Bu3aV8oDR8"
      },
      "source": [
        "checkpoint={\n",
        "    'input_size':[3,32,32],\n",
        "    'output_size':10,\n",
        "    'state_dict': model.state_dict()\n",
        "}\n",
        "torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuyqPxgtojNk"
      },
      "source": [
        "dict1=pickle.load('/content/checkpoint.pth')\n",
        "model.load_state_dict(dict1['state_dict'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RX6cvh2l_zK"
      },
      "source": [
        "def calculate_acc_auc(actual, prediction):\n",
        "  prediction=torch.argmax(prediction,dim=1)\n",
        "  return accuracy_score(actual.tolist().copy(), prediction.tolist().copy())#, roc_auc_score(actual.tolist().copy(), prediction_prob.tolist().copy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwGwoVkDURWm"
      },
      "source": [
        "acc_1=[]\n",
        "for images,labels in test_loader:\n",
        "  optimizer.zero_grad()\n",
        "  logits=model(images)\n",
        "  acc = calculate_acc_auc(labels, logits)\n",
        "  acc_1.append(acc)\n",
        "  #print(acc)\n",
        "\n",
        "print(\"avg acc\", sum(acc_1)/len(acc_1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9FIb3QJpDcT"
      },
      "source": [
        "# Transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924,
          "referenced_widgets": [
            "5b03456f70f5458885da0fb57858bc7a",
            "ad2c177b01e34d28baf9ea18b76456a3",
            "6dfd8cabb6244979b13202b86c028a85",
            "8fedb822cefb427dbf1193c10ce7305f",
            "ff9a1b4a08774c439e96cb38cb4a7247",
            "4486347bdd1c4af69f4516c766f524a6",
            "37dcf61b9ccc444b8f601f2f004f60a1",
            "327fa719da964db79316a460174fa836"
          ]
        },
        "id": "jCxs4XvUpH_x",
        "outputId": "beb0c285-3be9-46be-bab7-ad0321dcc7f3"
      },
      "source": [
        "from torchvision import models\n",
        "model=models.vgg16(pretrained=True)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b03456f70f5458885da0fb57858bc7a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rnGHtjQvbUL",
        "outputId": "22ac32b2-5dee-4ab0-eb91-de2351529d0b"
      },
      "source": [
        "#print(model.features) #view convolution layer\n",
        "print(model.classifier) #view classification layer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Dropout(p=0.5, inplace=False)\n",
            "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): Dropout(p=0.5, inplace=False)\n",
            "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUtlEr6tvk5F"
      },
      "source": [
        "#freese training for all cnn layers\n",
        "for param in model.features.parameters():\n",
        "  param.requires_grad=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTnA8exuwAOW"
      },
      "source": [
        "#vgg16 is used for image net->1000 classes,\n",
        "#we make it train for cifar 10 -> 10 classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi0XKQ5zwRec",
        "outputId": "f0df1921-cdcf-4b36-af9a-20e0bad828bf"
      },
      "source": [
        "n_classes=10\n",
        "in_features=model.classifier[6].in_features\n",
        "\n",
        "last_layer = nn.Linear(in_features, n_classes)\n",
        "model.classifier[6]=last_layer\n",
        "print(model.classifier[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=4096, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shIrQowayJlu",
        "outputId": "8291e5cd-b087-46fb-da6e-54b4010bf733"
      },
      "source": [
        "a=torch.randn(2,1,3,1).squeeze()\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.4889,  0.2477, -0.1475],\n",
            "        [ 0.3084,  0.6662, -1.2789]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2XG3mnOgWU1"
      },
      "source": [
        "# RNN (text generation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtcqGsbtgZxd",
        "outputId": "4614655d-e930-456a-8366-4e0e735316ec"
      },
      "source": [
        "!wget https://www.gutenberg.org/cache/epub/11/pg11.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-18 04:06:18--  https://www.gutenberg.org/cache/epub/11/pg11.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 406 Not Acceptable\n",
            "2021-03-18 04:06:19 ERROR 406: Not Acceptable.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhdb16GDgh3t"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/Neural Networks Practice/wonderland.txt\" \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be__hIrKhcQP"
      },
      "source": [
        "txt_file=\"/content/wonderland.txt\"\n",
        "text=open(txt_file, 'r', encoding='utf-8').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrvIdubrh2ob",
        "outputId": "2c160518-337b-4152-88d5-36092841772d"
      },
      "source": [
        "type(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeKHgxFZipnj"
      },
      "source": [
        "text=text.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD2IAiPmirul"
      },
      "source": [
        "#remove punnctuations\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNBSm26UzDRR"
      },
      "source": [
        "word_list=tokenizer.tokenize(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUTX8feYzOEw"
      },
      "source": [
        "text=' '.join(word_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z11c-xeWzTL_"
      },
      "source": [
        "#making a mapping\n",
        "chars=sorted(list(set(text)))\n",
        "maps=dict((c,i) for i,c in enumerate(chars))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEFGs0RSzyZt",
        "outputId": "55946323-b3dd-48c3-9bb1-d1d8df3e73bf"
      },
      "source": [
        "n_chars = len(text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  135061\n",
            "Total Vocab:  30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ8Qb3Gw2hAy"
      },
      "source": [
        "seq_len=10\n",
        "x_list=[]\n",
        "y_list=[]\n",
        "for i in range(n_chars-seq_len):\n",
        "  x_list.append(text[i:seq_len+i])\n",
        "  y_list.append(text[seq_len+i])\n",
        "\n",
        "assert len(x_list)==len(y_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wm_uLm84aqf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3350c2b2-6526-4d37-927d-091485e416ef"
      },
      "source": [
        "\"\"\"\n",
        "Since strings cannot be converted to tensors, we convert each character \n",
        "to an integer tensor.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nSince strings cannot be converted to tensors, we convert each character \\nto an integer tensor.\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gdht9yE4s-h"
      },
      "source": [
        "x_list_int=[ [maps[i] for i in x_list[j]] for j in range(len(x_list)) ]\n",
        "y_list_int=[ maps[y_list[j]] for j in range(len(y_list)) ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKVY8w2t37H1"
      },
      "source": [
        "class Tdataset(data.Dataset):\n",
        "  def __init__(self, x_list_int,y_list_int ):\n",
        "    self.x_data = torch.tensor(x_list_int,\n",
        "      dtype=torch.int32).to(device)\n",
        "    self.y_data = torch.tensor(y_list_int,\n",
        "      dtype=torch.int32).to(device)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)  # required\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if torch.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "    preds = self.x_data[idx]\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1tKZPyK5rMZ"
      },
      "source": [
        "train_data=Tdataset(x_list_int,y_list_int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXLlU5xvO2D9",
        "outputId": "c137894a-855a-4d67-8250-eb6e1257a11d"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135051"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nl-i-BIRGgR"
      },
      "source": [
        "batch_size=32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzYyTf1Z7c5t"
      },
      "source": [
        "train_loader=data.DataLoader(train_data,batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyI2ekjz7txz"
      },
      "source": [
        "class net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    ##################### input features, \n",
        "    self.lstm1 = nn.LSTM(input_size = 10, hidden_size = seq_len, num_layers =2) \n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    self.linear1 = nn.Linear(256,n_vocab)\n",
        "  def forward(self,x):\n",
        "    x=self.lstm1(x)\n",
        "    #print(\"after lstm \", x.shape)\n",
        "    x=self.dropout(x)\n",
        "    #print(\"after lstm \", x.shape)\n",
        "\n",
        "    x=self.softmax(self.linear1(x),dim=1)\n",
        "    print(\"after softmax \", x.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfoKUZMLRyUX",
        "outputId": "ed852f17-6f89-4c50-8e07-2aad38f4ba4b"
      },
      "source": [
        "model= net()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "net(\n",
            "  (lstm1): LSTM(10, 10, num_layers=2)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (linear1): Linear(in_features=256, out_features=30, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "sNatuOEFVLKJ",
        "outputId": "a8733017-eb4f-4827-d715-04a3c6bfcfde"
      },
      "source": [
        "a=torch.rand([32,1,10])\n",
        "print(type(a))\n",
        "model(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-2ea0182a1d9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-7a37a28f584a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#print(\"after lstm \", x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m#print(\"after lstm \", x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: dropout(): argument 'input' (position 1) must be Tensor, not tuple"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V12aO2IgQq2d"
      },
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(params=model.parameters(),lr=0.03)\n",
        "epochs=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqTxdGuGRaEr"
      },
      "source": [
        "for e in range(epochs):\n",
        "  for x,y in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    print(x.shape)\n",
        "    logits=model(x)\n",
        "    loss=criterion(logits,y)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c2nlpaMhZ-8"
      },
      "source": [
        "# GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCkbIxRbRvXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f8ebbbf-e259-4f00-95a7-92dd9fa12ded"
      },
      "source": [
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-25 07:25:51--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-03-25 07:25:51--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: â€˜MNIST.tar.gzâ€™\n",
            "\n",
            "MNIST.tar.gz            [      <=>           ]  33.20M  29.2MB/s    in 1.1s    \n",
            "\n",
            "2021-03-25 07:25:53 (29.2 MB/s) - â€˜MNIST.tar.gzâ€™ saved [34813078]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LZqm-2esvSP",
        "outputId": "4da1a756-e7fc-4d59-803d-a3f86ede5eb4"
      },
      "source": [
        "!tar -zxvf MNIST.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_2xI5jAsxrw",
        "outputId": "8c38bf28-d00a-409e-f989-df4041e60180"
      },
      "source": [
        "root_dir = './'\n",
        "datasets.MNIST(root=root_dir,download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./\n",
              "    Split: Train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRoHIWjXtFms"
      },
      "source": [
        "train_set = datasets.MNIST(root=root_dir, train=True, download=False, transform=transforms.ToTensor())\n",
        "test_set = datasets.MNIST(root=root_dir, train=False, download=False, transform=transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ab8AL5GtRai"
      },
      "source": [
        "train_loader = data.DataLoader(train_set,batch_size=64,shuffle=True)\n",
        "test_loader = data.DataLoader(test_set,batch_size=64,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "imDcMI3btZjc",
        "outputId": "be96e3ac-bd27-4340-a574-c1dc03c6bb53"
      },
      "source": [
        "data_iter=iter(train_loader)\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "plt.imshow(images[0].numpy().squeeze(), cmap='Greys_r')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5b489ced10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skfrwh24t5da"
      },
      "source": [
        "class Descriminator(nn.Module):\n",
        "  def __init__(self,inp):\n",
        "    super().__init__()\n",
        "    self.fc1=nn.Linear(inp,1024)\n",
        "    self.fc2=nn.Linear(self.fc1.out_features,self.fc1.out_features*2)\n",
        "    self.fc3=nn.Linear(self.fc2.out_features,self.fc2.out_features*2)\n",
        "    self.fc4=nn.Linear(self.fc3.out_features,1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=f.leaky_relu(self.fc1(x),0.2)\n",
        "    x=f.dropout(x,0.3)\n",
        "    x=f.leaky_relu(self.fc2(x),0.2)\n",
        "    x=f.dropout(x,0.3)\n",
        "    x=f.leaky_relu(self.fc3(x),0.2)\n",
        "    x=f.dropout(x,0.3)\n",
        "    return torch.sigmoid(self.fc4(x))\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self,inp,out):\n",
        "    super().__init__()\n",
        "    self.fc1=nn.Linear(inp,256)\n",
        "    self.fc2=nn.Linear(self.fc1.out_features,self.fc1.out_features*2)\n",
        "    self.fc3=nn.Linear(self.fc2.out_features,self.fc2.out_features*2)\n",
        "    self.fc4=nn.Linear(self.fc3.out_features,out)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=f.leaky_relu(self.fc1(x),0.2)\n",
        "    x=f.leaky_relu(self.fc2(x),0.2)\n",
        "    x=f.leaky_relu(self.fc3(x),0.2)\n",
        "    return torch.tanh(self.fc4(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oti0a1sVvtO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "710a5e08-20ca-4a7d-c437-f1b7e7dc0252"
      },
      "source": [
        "D=Descriminator(28*28).to(device)\n",
        "G=Generator(100,28*28).to(device)\n",
        "print(D)\n",
        "print(G)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Descriminator(\n",
            "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=2048, bias=True)\n",
            "  (fc3): Linear(in_features=2048, out_features=4096, bias=True)\n",
            "  (fc4): Linear(in_features=4096, out_features=1, bias=True)\n",
            ")\n",
            "Generator(\n",
            "  (fc1): Linear(in_features=100, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
            "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=784, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smO8uogjv3Eo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c22e9d38-b1ed-4fc1-9b5a-be345fd068f5"
      },
      "source": [
        "data_iter=iter(train_loader)\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "images.resize(64,1,784) #(batch_size,channels, image pixels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/tensor.py:474: UserWarning: non-inplace resize is deprecated\n",
            "  warnings.warn(\"non-inplace resize is deprecated\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0.,  ..., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc5ezPz2i0ah"
      },
      "source": [
        "# loss\n",
        "criterion = nn.BCELoss() \n",
        "\n",
        "# optimizer\n",
        "lr = 0.0002 \n",
        "G_optimizer = optim.Adam(G.parameters(), lr = lr)\n",
        "D_optimizer = optim.Adam(D.parameters(), lr = lr)\n",
        "epochs=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgAnXgQbwhCf"
      },
      "source": [
        "def D_train(real_images,real_labels):\n",
        "  real_images=real_images.view(real_images.shape[0],-1).to(device) #reshaping to (64,784)\n",
        "  D_optimizer.zero_grad() #clearing up the gradients of previous iteration\n",
        "  real_logits=D.forward(real_images).squeeze().to(device)\n",
        "  real_labels = real_labels.to(torch.float32).to(device)\n",
        "  real_loss=criterion(real_logits,real_labels).to(device)\n",
        "  rand_tensor=torch.randn((64,100)).to(device) # batch_size, i/p dim of G\n",
        "  \n",
        "  fake_images=G.forward(rand_tensor).to(device) # generating images using Generator\n",
        "  fake_label=torch.full((64,1),fill_value=10).type(torch.float32).squeeze().to(device)\n",
        "  fake_logits=D.forward(fake_images).squeeze().to(device)\n",
        "  fake_loss=criterion(fake_logits,fake_label)\n",
        "  D_loss=real_loss+fake_loss\n",
        "  D_loss.backward()\n",
        "  D_optimizer.step()\n",
        "  return  D_loss.data.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3xBagfKOPVo"
      },
      "source": [
        "def G_train():\n",
        "  G.zero_grad()\n",
        "  rand_tensor=torch.randn(64,100).to(device) # batch_size, i/p dim of G\n",
        "  fake_label=torch.full((64,1),fill_value=10).type(torch.float32).squeeze().to(device)\n",
        "\n",
        "  image=G.forward(rand_tensor).to(device)\n",
        "  logit=D.forward(image).squeeze().to(device)\n",
        "  G_loss=criterion(logit,fake_label)\n",
        "\n",
        "  # gradient backprop & optimize ONLY G's parameters\n",
        "  G_loss.backward()\n",
        "  G_optimizer.step()\n",
        "      \n",
        "  return G_loss.data.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85iH62BQPYQv",
        "outputId": "d16a8a35-6e2f-4bda-9d74-78d9fbf54aa9"
      },
      "source": [
        "n_epoch = 10\n",
        "for epoch in range(1, n_epoch+1):           \n",
        "    D_losses, G_losses = [], []\n",
        "    for batch_idx, (image,labels) in enumerate(train_loader):\n",
        "        D_losses.append(D_train(image.to(device),labels.to(device)))\n",
        "        G_losses.append(G_train())\n",
        "\n",
        "    print('[%d/%d]: loss_d: %.3f, loss_g: %.3f' % (\n",
        "            (epoch), n_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/10]: loss_d: 1.480, loss_g: 0.696\n",
            "[2/10]: loss_d: 1.480, loss_g: 0.696\n",
            "[3/10]: loss_d: 1.479, loss_g: 0.696\n",
            "[4/10]: loss_d: 1.480, loss_g: 0.696\n",
            "[5/10]: loss_d: 1.480, loss_g: 0.696\n",
            "[6/10]: loss_d: 1.479, loss_g: 0.696\n",
            "[7/10]: loss_d: 1.480, loss_g: 0.696\n",
            "[8/10]: loss_d: 1.480, loss_g: 0.696\n",
            "[9/10]: loss_d: 1.480, loss_g: 0.696\n",
            "[10/10]: loss_d: 1.480, loss_g: 0.696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozZzR2-vsobv"
      },
      "source": [
        "checkpoint={\n",
        "    'input_size':[28,28],\n",
        "    'output_size':1,\n",
        "    'state_dict': D.state_dict()\n",
        "}\n",
        "torch.save(checkpoint, 'Descriminator_checkpoint.pth')\n",
        "\n",
        "checkpoint={\n",
        "    'input_size':[100,28*28],\n",
        "    'output_size':1,\n",
        "    'state_dict': G.state_dict()\n",
        "}\n",
        "torch.save(checkpoint, 'Generator_checkpoint.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWXi2D3cTpQa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}